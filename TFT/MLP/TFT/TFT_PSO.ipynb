{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f592910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD\n",
    "import torch.utils.data as Data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data=pd.read_excel('C:/Users/XHM/Desktop/data/TFT/TFT_train.xlsx',engine='openpyxl')\n",
    "all_input=data[['Vdrain','Vgate','W/L']].values\n",
    "#all_output=data['Idrain']\n",
    "minmax=preprocessing.MinMaxScaler()\n",
    "all_output=minmax.fit_transform(data['Idrain'].values.reshape(-1,1))\n",
    "\n",
    "(x_train,x_test,y_train,y_test)=train_test_split(all_input,all_output,train_size=0.8,\n",
    "                                                 random_state=0)\n",
    "#标准化处理\n",
    "scale=StandardScaler()\n",
    "x_train_s=minmax.fit_transform(x_train)\n",
    "x_test_s=minmax.fit_transform(x_test)\n",
    "\n",
    "\n",
    "\n",
    "#数据类型处理\n",
    "train_xt=torch.from_numpy(x_train_s.astype(np.float32))\n",
    "train_yt=torch.from_numpy(y_train)\n",
    "test_xt=torch.from_numpy(x_test_s.astype(np.float32))\n",
    "test_yt=torch.from_numpy(y_test)\n",
    "#将数据处理为数据加载器\n",
    "train_data=Data.TensorDataset(train_xt,train_yt.float())\n",
    "test_data=Data.TensorDataset(test_xt,test_yt.float())\n",
    "\n",
    "train_loader=Data.DataLoader(dataset=train_data,batch_size=64,shuffle=True,num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41f55ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "#搭建MLP回归模型\n",
    "class MLPregression(nn.Module):\n",
    "    def __init__(self,p):\n",
    "        super(MLPregression,self).__init__()\n",
    "        self.p=p\n",
    "        #定义第一个隐藏层\n",
    "        self.input=nn.Linear(in_features=3,out_features=60,bias=True)\n",
    "        #定义第二个隐藏层\n",
    "        self.hidden2=nn.Linear(60,100)\n",
    "        #回归预测层\n",
    "        self.predict=nn.Linear(100,1)\n",
    "        \n",
    "        self.input.weight.data=self.p[0:180].reshape((60,3))\n",
    "        self.input.bias.data=self.p[180:240].reshape((60,))\n",
    "        self.hidden2.weight.data=self.p[240:6240].reshape((100,60))\n",
    "        self.hidden2.bias.data=self.p[6240:6340].reshape((100,))\n",
    "        self.predict.weight.data=self.p[6340:6440].reshape((1,100))\n",
    "        self.predict.bias.data=self.p[6440:6441]\n",
    "    def forward(self,x):\n",
    "        x=torch.tanh(self.input(x))\n",
    "        x=torch.tanh(self.hidden2(x))\n",
    "        output=self.predict(x)\n",
    "        return output[:,0]\n",
    "        \n",
    "#mlpreg.load_state_dict(torch.load(\"C:/Users/XHM/LEVIST/DIST/mlp_init_nosgd.pth\"))\n",
    "\n",
    "def fitness(x):\n",
    "    mlpreg=MLPregression(p=x) \n",
    "    loss_func=nn.MSELoss()\n",
    "    train_loss_all=[]\n",
    "    for step,(b_x,b_y) in enumerate(train_loader):\n",
    "        output=mlpreg(b_x)\n",
    "        loss=loss_func(output,b_y)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "155f39ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Install\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([64, 1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############ Generation 1 ############\n",
      "最好的位置：tensor([0.0011, 0.0011, 0.0011,  ..., 0.0011, 0.0011, 0.0011])\n",
      "最小的loss：0.04176587611436844\n",
      "############ Generation 2 ############\n",
      "最好的位置：tensor([0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010])\n",
      "最小的loss：0.005079639609903097\n",
      "############ Generation 3 ############\n",
      "最好的位置：tensor([0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010])\n",
      "最小的loss：0.021133821457624435\n",
      "############ Generation 4 ############\n",
      "最好的位置：tensor([0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010])\n",
      "最小的loss：0.057389914989471436\n",
      "############ Generation 5 ############\n",
      "最好的位置：tensor([0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0477])\n",
      "最小的loss：0.036705754697322845\n",
      "############ Generation 6 ############\n",
      "最好的位置：tensor([0.0029, 0.0029, 0.0029,  ..., 0.0029, 0.0029, 0.0010])\n",
      "最小的loss：0.02594926953315735\n",
      "############ Generation 7 ############\n",
      "最好的位置：tensor([0.0029, 0.0029, 0.0029,  ..., 0.0029, 0.0029, 0.0010])\n",
      "最小的loss：0.017309419810771942\n",
      "############ Generation 8 ############\n",
      "最好的位置：tensor([0.0029, 0.0029, 0.0029,  ..., 0.0029, 0.0029, 0.0010])\n",
      "最小的loss：0.024804944172501564\n",
      "############ Generation 9 ############\n",
      "最好的位置：tensor([0.0029, 0.0029, 0.0029,  ..., 0.0029, 0.0029, 0.0010])\n",
      "最小的loss：0.013044150546193123\n",
      "############ Generation 10 ############\n",
      "最好的位置：tensor([0.0029, 0.0029, 0.0029,  ..., 0.0029, 0.0029, 0.0010])\n",
      "最小的loss：0.009224303998053074\n",
      "############ Generation 11 ############\n",
      "最好的位置：tensor([0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010])\n",
      "最小的loss：0.03314107656478882\n",
      "############ Generation 12 ############\n",
      "最好的位置：tensor([0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010])\n",
      "最小的loss：0.03930880129337311\n",
      "############ Generation 13 ############\n",
      "最好的位置：tensor([0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010])\n",
      "最小的loss：0.01941066049039364\n",
      "############ Generation 14 ############\n",
      "最好的位置：tensor([0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010])\n",
      "最小的loss：0.02786700427532196\n",
      "############ Generation 15 ############\n",
      "最好的位置：tensor([0.0029, 0.0029, 0.0029,  ..., 0.0029, 0.0030, 0.0053])\n",
      "最小的loss：0.02059089206159115\n",
      "############ Generation 16 ############\n",
      "最好的位置：tensor([0.0044, 0.0044, 0.0044,  ..., 0.0045, 0.0046, 0.0090])\n",
      "最小的loss：0.023414574563503265\n",
      "############ Generation 17 ############\n",
      "最好的位置：tensor([0.0044, 0.0044, 0.0044,  ..., 0.0045, 0.0046, 0.0090])\n",
      "最小的loss：0.029555819928646088\n",
      "############ Generation 18 ############\n",
      "最好的位置：tensor([0.0044, 0.0044, 0.0044,  ..., 0.0045, 0.0046, 0.0090])\n",
      "最小的loss：0.025417029857635498\n",
      "############ Generation 19 ############\n",
      "最好的位置：tensor([0.0161, 0.0161, 0.0161,  ..., 0.0159, 0.0157, 0.0010])\n",
      "最小的loss：0.02479877509176731\n",
      "############ Generation 20 ############\n",
      "最好的位置：tensor([0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0137])\n",
      "最小的loss：0.043498970568180084\n",
      "############ Generation 21 ############\n",
      "最好的位置：tensor([0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0137])\n",
      "最小的loss：0.026758810505270958\n",
      "############ Generation 22 ############\n",
      "最好的位置：tensor([0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0137])\n",
      "最小的loss：0.0158124640583992\n",
      "############ Generation 23 ############\n",
      "最好的位置：tensor([0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0137])\n",
      "最小的loss：0.046441640704870224\n",
      "############ Generation 24 ############\n",
      "最好的位置：tensor([0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0137])\n",
      "最小的loss：0.019048191606998444\n",
      "############ Generation 25 ############\n",
      "最好的位置：tensor([0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0137])\n",
      "最小的loss：0.013705057092010975\n",
      "############ Generation 26 ############\n",
      "最好的位置：tensor([0.0117, 0.0185, 0.0187,  ..., 0.0115, 0.0010, 0.0011])\n",
      "最小的loss：0.013655077666044235\n",
      "############ Generation 27 ############\n",
      "最好的位置：tensor([0.0117, 0.0185, 0.0187,  ..., 0.0115, 0.0010, 0.0011])\n",
      "最小的loss：0.02194143831729889\n",
      "############ Generation 28 ############\n",
      "最好的位置：tensor([0.0036, 0.0010, 0.0010,  ..., 0.0010, 0.0022, 0.0010])\n",
      "最小的loss：0.017170438542962074\n",
      "############ Generation 29 ############\n",
      "最好的位置：tensor([0.0036, 0.0010, 0.0010,  ..., 0.0010, 0.0022, 0.0010])\n",
      "最小的loss：0.021252388134598732\n",
      "############ Generation 30 ############\n",
      "最好的位置：tensor([0.0014, 0.0010, 0.0010,  ..., 0.0010, 0.0029, 0.0010])\n",
      "最小的loss：0.009853863157331944\n",
      "############ Generation 31 ############\n",
      "最好的位置：tensor([0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0087])\n",
      "最小的loss：0.047062695026397705\n",
      "############ Generation 32 ############\n",
      "最好的位置：tensor([0.0030, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0068])\n",
      "最小的loss：0.042507778853178024\n",
      "############ Generation 33 ############\n",
      "最好的位置：tensor([0.0030, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0068])\n",
      "最小的loss：0.016341784968972206\n",
      "############ Generation 34 ############\n",
      "最好的位置：tensor([0.0019, 0.0017, 0.0013,  ..., 0.0065, 0.0010, 0.0010])\n",
      "最小的loss：0.021514426916837692\n",
      "############ Generation 35 ############\n",
      "最好的位置：tensor([0.0019, 0.0017, 0.0013,  ..., 0.0065, 0.0010, 0.0010])\n",
      "最小的loss：0.04716833308339119\n",
      "############ Generation 36 ############\n",
      "最好的位置：tensor([0.0019, 0.0017, 0.0013,  ..., 0.0065, 0.0010, 0.0010])\n",
      "最小的loss：0.05645864084362984\n",
      "############ Generation 37 ############\n",
      "最好的位置：tensor([0.0052, 0.0010, 0.0010,  ..., 0.0010, 0.0012, 0.0010])\n",
      "最小的loss：0.009535827673971653\n",
      "############ Generation 38 ############\n",
      "最好的位置：tensor([0.0052, 0.0010, 0.0010,  ..., 0.0010, 0.0012, 0.0010])\n",
      "最小的loss：0.018135350197553635\n",
      "############ Generation 39 ############\n",
      "最好的位置：tensor([0.0052, 0.0010, 0.0010,  ..., 0.0010, 0.0012, 0.0010])\n",
      "最小的loss：0.028265252709388733\n",
      "############ Generation 40 ############\n",
      "最好的位置：tensor([0.0019, 0.0021, 0.0010,  ..., 0.0010, 0.0063, 0.0137])\n",
      "最小的loss：0.03350365534424782\n",
      "############ Generation 41 ############\n",
      "最好的位置：tensor([0.0039, 0.0010, 0.0010,  ..., 0.0014, 0.0010, 0.0010])\n",
      "最小的loss：0.025048332288861275\n",
      "############ Generation 42 ############\n",
      "最好的位置：tensor([0.0039, 0.0010, 0.0010,  ..., 0.0014, 0.0010, 0.0010])\n",
      "最小的loss：0.014195559546351433\n",
      "############ Generation 43 ############\n",
      "最好的位置：tensor([0.0010, 0.0010, 0.0011,  ..., 0.0010, 0.0047, 0.0282])\n",
      "最小的loss：0.02422419562935829\n",
      "############ Generation 44 ############\n",
      "最好的位置：tensor([0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0255])\n",
      "最小的loss：0.011485738679766655\n",
      "############ Generation 45 ############\n",
      "最好的位置：tensor([0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0255])\n",
      "最小的loss：0.04192410781979561\n",
      "############ Generation 46 ############\n",
      "最好的位置：tensor([0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0255])\n",
      "最小的loss：0.05078154802322388\n",
      "############ Generation 47 ############\n",
      "最好的位置：tensor([0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0255])\n",
      "最小的loss：0.009080251678824425\n",
      "############ Generation 48 ############\n",
      "最好的位置：tensor([0.0010, 0.0010, 0.0020,  ..., 0.0010, 0.0010, 0.0213])\n",
      "最小的loss：0.03455222025513649\n",
      "############ Generation 49 ############\n",
      "最好的位置：tensor([0.0010, 0.0010, 0.0020,  ..., 0.0010, 0.0010, 0.0213])\n",
      "最小的loss：0.01864812523126602\n",
      "############ Generation 50 ############\n",
      "最好的位置：tensor([0.0010, 0.0010, 0.0020,  ..., 0.0010, 0.0010, 0.0213])\n",
      "最小的loss：0.030110402032732964\n",
      "---- End of (successful) Searching ----\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'detach'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17512/165773624.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[0mparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0miters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpopsize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mup\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[0mpso\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPSO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m     \u001b[0mpso\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17512/165773624.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"fitness\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpopobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'b'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'detach'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEaCAYAAAAG87ApAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAV0klEQVR4nO3df7AlZX3n8feHQSQIYgyDmAEEdRAHYgQnoOsu4ooJkgSS0nIhRRQlsnHFuGvWAo2FFJrs4o8YzZLoWKKJKfmh2dXZgOKahWVF0RkVEcZgjaAyYGQABQVlBL/7R/fde7iZmXue4d6+5859v6pOTZ/u53R/56k787lPd5+nU1VIkjSuXRa6AEnS4mJwSJKaGBySpCYGhySpicEhSWpicEiSmhgc0jYk+XGSJy90HdKkMTgkIMm3k/ykD4sfJ/kxcEhV3bwAteyW5ON9TZXk2KFrkLbH4JCm/XZV7Tnyun0+DpJk1zGafQ44Ffjn+ahBeiQMDmkb+t/2n9ov/1KS/5nk3iTrkrwtyef6bQf1bXcd+exVSf6gXz4tyTVJ3p3kLuDcJI9O8s4k303y/STvS/ILAFW1par+oqo+Bzw0/N9c2j6DQxrPBcB9wH7Ay/tXi6OBm4EnAH8K/FfgEOCZwFOBFcA5c1SrNK/GGTJLS8UnkjzYL181tTLJMuDFwOFVdT+wIcnfAMc27Pv2qvrLfn8PAWcAz6iqu/t1fwZ8FHjjI/1LSPPN4JCm/U5VfXbqTZKpGUCX0/1buXWk7ejyOEbbLwf2AL6c5P8fDljWuE9pQXiqSprdZuBBYP+RdQeMLN/X/7nHyLr9ZuxjdBrqO4GfAIdV1eP6195VtedcFSzNJ4NDmkVVPQT8d7qL2nskORR42cj2zcBtwKlJliV5JfCU7ezv58AHgHcn2RcgyYokvzHVpr94vnv/drcku2dkeCItJINDGs+ZwN50t8d+BLgIeGBk+6uANwB3AYcBn59lf2cBG4Frk9wLfBZ42sj2m+hGJSuAK/rlJz3iv4U0B+KDnKR2Sc4H9quq1rurpEXPEYc0hiSHJnlGOkcBpwP/Y6HrkhbCYMGR5MIkdyS5YRvbk+S9STYmuT7JkUPVJo1hL7rrHPcBlwDvAj65oBVJC2SwU1VJjgF+DPxtVR2+le0nAK8FTqD7stR7quroQYqTJI1tsBFHVV0N3L2dJifRhUpV1bXA45I8cZjqJEnjmqQvAK7g4V+S2tSv+97MhknOoPvmLY95zGOedeihhw5SoCTtLL785S/fWVXLd+SzkxQcY6uqNcAagNWrV9f69esXuCJJWlySfGdHPztJd1XdxsO/jbt/v06SNEEmKTjWAi/r7656NnBPVf2L01SSpIU12KmqJBfRzSa6T5JNwFuARwFU1fuAy+nuqNoI3A+8YqjaJEnjGyw4quqUWbYX8JqBypEk7aBJOlUlSVoEDA5JUhODQ5LUxOCQJDUxOCRJTQwOSVITg0OS1MTgkCQ1MTgkSU0MDklSE4NDktTE4JAkNTE4JElNDA5JUhODQ5LUxOCQJDUxOCRJTQwOSVITg0OS1MTgkCQ1MTgkSU0MDklSE4NDktTE4JAkNTE4JElNDA5JUhODQ5LUxOCQJDUxOCRJTQwOSVITg0OS1MTgkCQ1MTgkSU0MDklSE4NDktRk0OBIcnySm5JsTHL2VrYfmOTKJF9Ncn2SE4asT5I0u8GCI8ky4ALgRcAq4JQkq2Y0ezNwaVUdAZwM/NVQ9UmSxjPkiOMoYGNV3VxVW4CLgZNmtCngsf3y3sDtA9YnSRrDkMGxArh15P2mft2oc4FTk2wCLgdeu7UdJTkjyfok6zdv3jwftUqStmHSLo6fAny4qvYHTgA+kuRf1FhVa6pqdVWtXr58+eBFStJSNmRw3AYcMPJ+/37dqNOBSwGq6gvA7sA+g1QnSRrLkMGxDliZ5OAku9Fd/F47o813gRcAJHk6XXB4LkqSJshgwVFVDwJnAlcA36C7e+rGJOclObFv9sfAq5J8DbgIOK2qaqgaJUmz23XIg1XV5XQXvUfXnTOyvAF47pA1SZLaTNrFcUnShDM4JElNDA5JUhODQ5LUxOCQJDUxOCRJTQwOSVITg0OS1MTgkCQ1MTgkSU0MDklSE4NDktTE4JAkNTE4JElNDA5JUhODQ5LUxOCQJDUxOCRJTQwOSVITg0OS1MTgkCQ1MTgkSU0MDklSE4NDktTE4JAkNTE4JElNDA5JUhODQ5LUxOCQJDUxOCRJTQwOSVITg0OS1MTgkCQ1MTgkSU0GDY4kxye5KcnGJGdvo81Lk2xIcmOSjw5ZnyRpdrsOdaAky4ALgBcCm4B1SdZW1YaRNiuBNwLPraofJNl3qPokSeMZcsRxFLCxqm6uqi3AxcBJM9q8Crigqn4AUFV3DFifJGkMQwbHCuDWkfeb+nWjDgEOSXJNkmuTHL+1HSU5I8n6JOs3b948T+VKkrbmEQVHkkfNVSG9XYGVwLHAKcAHkjxuZqOqWlNVq6tq9fLly+e4BEnS9owdHEn+KMmLR95/EPhJf7H7aWPs4jbggJH3+/frRm0C1lbVz6rqFuCbdEEiSZoQLSOOPwI2AyQ5Bngp8HvAdcC7xvj8OmBlkoOT7AacDKyd0eYTdKMNkuxDd+rq5oYaJUnzrOWuqhXALf3ybwMfq6pLk3wd+L+zfbiqHkxyJnAFsAy4sKpuTHIesL6q1vbbfj3JBuAh4A1VdVdDjZKkedYSHPcC+9Jd4H4h8I5+/c+A3cfZQVVdDlw+Y905I8sFvL5/SZImUEtwfIbuYvVXgKcCn+rXH8b0SESStJNrucbxGuAaYDnwkqq6u19/JHDRXBcmSZpMY484qupe4LVbWf+WOa1IkjTRWm7HXTV6222SFyb5uyRv7KcTkSQtAS2nqi4EjgBIcgDwSeDxdKew3jb3pUmSJlFLcBwKfKVffgnwxao6Afh9um95S5KWgJbgWAZs6ZdfwPRttd8CnjCXRUmSJldLcNwAvDrJv6ELjk/361cAd851YZKkydQSHGfRTXt+FXBRVX29X38i8KU5rkuSNKFabse9Osly4LFTz8vovR+4f84rkyRNpKZp1avqIWBZkqOTPLpf920fuCRJS0fL9zj2SvIx4A7g8/QPYUryviTnzk95kqRJ0zLiOB/4ZbopRn4ysv4fgN+dy6IkSZOrZZLDE4HfrarrktTI+m8AT57bsiRJk6plxPGLwNaejbEX3bMzJElLQEtwrKMbdUyZGnX8e7prHpKkJaDlVNWbgCuSHNZ/7vX98lHAMfNRnCRp8ow94qiqzwP/CtiNbpqRFwC3A8+pqq9s77OSpJ1Hy4iD/tviL5+nWiRJi0BTcAAk+WW6Z48/bLTiqEOSloaxgyPJEcDf0U2vnhmbi272XEnSTq5lxLEGuJVuosPbmb6rSpK0hLQExyrgiKr65nwVI0mafC3f4/g6sN98FSJJWhxaguNNwNuTHJfkCUkeP/qarwIlSZOl5VTVZ/s/P8PDr28EL45L0pLREhzPn7cqJEmLRktw3ALcWlUPu5sqSYAD5rQqSdLEarnGcQuwfCvrH99vkyQtAS3BMXUtY6Y9gZ/OTTmSpEk366mqJO/tFwv4L0nuH9m8jG523OvmvjRJ0iQa5xrHr/R/Bng6sGVk2xbgK8A757guSdKEmjU4qur5AEk+BLyuqu6d96okSRNr7LuqquoV81mIJGlx2G5wJFkLnFpV9/bL21RVJ25vuyRp5zDbXVWHM30n1V2zvGaV5PgkNyXZmOTs7bR7cZJKsnqc/UqShjPbqaqDgF8AfgQ8D/i1qhorJGZKsgy4AHghsAlYl2RtVW2Y0W4v4HXAF3fkOJKk+TXbiONu4OB++aAx2m/PUcDGqrq5qrYAFwMnbaXdW4Hz8bshkjSRZhtx/D3wf5J8j+6U1fokD22tYVU9eZZ9raB7ENSUTcDRow2SHAkcUFWXJXnDtnaU5AzgDIADDzxwlsNKkubSbMHxh8BaYCXw58CH6E5bzbkku/THOG22tlW1hu6JhKxevdonEUrSgLYbHP2EhpcBJPlV4F1VtaPBcRsPnwxx/37dlL3oLsZf1c2byH7A2iQnVtX6HTymJGmODfk9jnXAyiQH0wXGycDvjez/HmCfqfdJrgL+s6EhSZPlkVzsblJVDwJnAlcA3wAuraobk5yXxO+ASNIi0fI8jkesqi4HLp+x7pxttD12iJokSW0GG3FIknYOBockqYnBIUlqYnBIkpoYHJKkJgaHJKmJwSFJamJwSJKaGBySpCYGhySpicEhSWpicEiSmhgckqQmBockqYnBIUlqYnBIkpoYHJKkJgaHJKmJwSFJamJwSJKaGBySpCYGhySpicEhSWpicEiSmhgckqQmBockqYnBIUlqYnBIkpoYHJKkJgaHJKmJwSFJamJwSJKaGBySpCYGhySpyaDBkeT4JDcl2Zjk7K1sf32SDUmuT/KPSZ40ZH2SpNkNFhxJlgEXAC8CVgGnJFk1o9lXgdVV9Qzg48Dbh6pPkjSeIUccRwEbq+rmqtoCXAycNNqgqq6sqvv7t9cC+w9YnyRpDEMGxwrg1pH3m/p123I68KmtbUhyRpL1SdZv3rx5DkuUJM1mIi+OJzkVWA28Y2vbq2pNVa2uqtXLly8ftjhJWuJ2HfBYtwEHjLzfv1/3MEmOA/4EeF5VPTBQbZKkMQ054lgHrExycJLdgJOBtaMNkhwBvB84saruGLA2SdKYBguOqnoQOBO4AvgGcGlV3ZjkvCQn9s3eAewJfCzJdUnWbmN3kqQFMuSpKqrqcuDyGevOGVk+bsh6JEntJvLiuCRpchkckqQmBockqYnBIUlqYnBIkpoYHJKkJgaHJKmJwSFJamJwSJKaGBySpCYGhySpicEhSWpicEiSmhgckqQmBockqYnBIUlqYnBIkpoYHJKkJgaHJKmJwSFJamJwSJKaGBySpCYGhySpicEhSWpicEiSmhgckqQmBockqYnBIUlqYnBIkpoYHJKkJgaHJKmJwSFJamJwSJKaGBySpCYGhySpyaDBkeT4JDcl2Zjk7K1sf3SSS/rtX0xy0JD1SZJmN1hwJFkGXAC8CFgFnJJk1YxmpwM/qKqnAu8Gzh+qPknSeIYccRwFbKyqm6tqC3AxcNKMNicBf9Mvfxx4QZIMWKMkaRa7DnisFcCtI+83AUdvq01VPZjkHuCXgDtHGyU5Azijf/tAkhvmpeLFZx9m9NUSZl9Msy+m2RfTnrajHxwyOOZMVa0B1gAkWV9Vqxe4pIlgX0yzL6bZF9Psi2lJ1u/oZ4c8VXUbcMDI+/37dVttk2RXYG/grkGqkySNZcjgWAesTHJwkt2Ak4G1M9qsBV7eL78E+N9VVQPWKEmaxWCnqvprFmcCVwDLgAur6sYk5wHrq2ot8EHgI0k2AnfThcts1sxb0YuPfTHNvphmX0yzL6btcF/EX+glSS385rgkqYnBIUlqsmiCw+lKpo3RF69PsiHJ9Un+McmTFqLOIczWFyPtXpykkuy0t2KO0xdJXtr/bNyY5KND1ziUMf6NHJjkyiRf7f+dnLAQdc63JBcmuWNb33VL5719P12f5MixdlxVE/+iu5j+LeDJwG7A14BVM9r8B+B9/fLJwCULXfcC9sXzgT365Vcv5b7o2+0FXA1cC6xe6LoX8OdiJfBV4Bf79/sudN0L2BdrgFf3y6uAby903fPUF8cARwI3bGP7CcCngADPBr44zn4Xy4jD6UqmzdoXVXVlVd3fv72W7jszO6Nxfi4A3ko379lPhyxuYOP0xauAC6rqBwBVdcfANQ5lnL4o4LH98t7A7QPWN5iqupruDtVtOQn42+pcCzwuyRNn2+9iCY6tTVeyYlttqupBYGq6kp3NOH0x6nS63yh2RrP2RT/0PqCqLhuysAUwzs/FIcAhSa5Jcm2S4werbljj9MW5wKlJNgGXA68dprSJ0/r/CbBIpxzReJKcCqwGnrfQtSyEJLsAfw6ctsClTIpd6U5XHUs3Cr06ya9U1Q8XsqgFcgrw4ap6V5Ln0H1/7PCq+vlCF7YYLJYRh9OVTBunL0hyHPAnwIlV9cBAtQ1ttr7YCzgcuCrJt+nO4a7dSS+Qj/NzsQlYW1U/q6pbgG/SBcnOZpy+OB24FKCqvgDsTjcB4lIz1v8nMy2W4HC6kmmz9kWSI4D304XGznoeG2bpi6q6p6r2qaqDquoguus9J1bVDk/uNsHG+TfyCbrRBkn2oTt1dfOANQ5lnL74LvACgCRPpwuOzYNWORnWAi/r7656NnBPVX1vtg8tilNVNX/TlSw6Y/bFO4A9gY/19wd8t6pOXLCi58mYfbEkjNkXVwC/nmQD8BDwhqra6UblY/bFHwMfSPKf6C6Un7Yz/qKZ5CK6Xxb26a/nvAV4FEBVvY/u+s4JwEbgfuAVY+13J+wrSdI8WiynqiRJE8LgkCQ1MTgkSU0MDklSE4NDktTE4NCSkeTDSf5hoeuQFjtvx9WSkWRvup/5Hya5im7G0DMHOvaxwJXA8qq6c4hjSvNlUXwBUJoLVXXPXO8zyW79DKyDSfKoqvrZkMeURnmqSkvG1KmqJB+mm/jxNf3DnWrqwV9JViW5LMmP+gfgXJRkv63s46z+m7ib+vWnJlk38rmPJVnRbzuIbrQBsLk/3of7bY9O8hdJvp/kp/2stf965HjH9u1PSPKlJFuA30hyQJJPJrk7yf1J/inJTjlbgiaPwaGl6HXAF4APAU/sX7f2zyG4GriB7pkOx9FN3fLJfqbdKc8DngEcTz/fEd0Dg94C/CrwW3QT5l3Ub7sVeHG/fFh/vNf1798O/DvglcARwNeBT2/lmQjnA28GDgW+CPwVsAfdQ7sOA/4j8MP2rpDaeapKS05V3dP/5n5/Vf3z1Pokrwa+VlVnjax7Gd3cZ6uBL/Wrfwq8cnTW4aq6cOQQN/f7+kaS/atqU5Kph+ncMXWNI8lj6J7Q+AdTzwtJ8ofAvwVeQxcUU86tqs+M1PUk4O+r6mv9qlt2tD+kVo44pGnPAo5J8uOpF9MPuXnKSLsbZk5Vn+TI/tTRd5L8CJiagffA7RzvKXQTzl0ztaKqHqIbDa2a0XbmjL7vAd6c5AtJ3pbkWeP8BaW5YHBI03YBLgOeOeO1Ehi9jfe+0Q/1I4cr6GYX/X3g1+hOY0F3CmtHzLzd8WHHrKoPAgfTnW47BPh8knN38FhSE4NDS9UWuim3R32F7nrBd6pq44zXj7azr0Pprmm8qaqurqp/AvbdyvGYccxv9eufO7UiyTLgOcCG2f4CVbWpqtZU1UuBc4AzZvuMNBcMDi1V3waOSnJQkn36i98X0D058pIkRyd5cpLjkqxJstd29vVd4AHgzP4zvwm8dUab79CNIn4zyfIke1bVfcBfA+f3d009vX//BLqL39uU5D1Jju+P90y6Ec6sYSPNBYNDS9U76X7b30D35LcDq+p2ut/+fw58GriRLkwe6F9bVVWb6Z4++Tv9/t4CvH5Gm9v69X8KfB/4b/2ms4BL6E45XUd/t9YYT2HbBfjL/nj/q9/ny7f7CWmO+M1xSVITRxySpCYGhySpicEhSWpicEiSmhgckqQmBockqYnBIUlqYnBIkpr8P/JAF1Zr5w5eAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "class PSO():\n",
    "    def __init__(self, parameters):\n",
    "        \"\"\"\n",
    "        particle swarm optimization\n",
    "        parameter: a list type, like [NGEN, pop_size, var_num_min, var_num_max]\n",
    "        \"\"\"\n",
    "        # 初始化\n",
    "        self.iters = parameters[0]    # 迭代的代数\n",
    "        self.pop_size = 100   # 种群大小\n",
    "        self.var_num =6441   # 变量个数\n",
    "        self.bound = []                 # 变量的约束范围\n",
    "        self.bound.append(parameters[2])\n",
    "        self.bound.append(parameters[3])\n",
    " \n",
    "        self.pop_x = torch.zeros((self.pop_size, self.var_num))    # 所有粒子的位置\n",
    "        self.pop_v = torch.zeros((self.pop_size, self.var_num))    # 所有粒子的速度\n",
    "        self.p_best = torch.zeros((self.pop_size, self.var_num))   # 每个粒子最优的位置\n",
    "        self.g_best = torch.zeros((self.var_num))   # 全局最优的位置\n",
    " \n",
    "        # 初始化第0代初始全局最优解\n",
    "        temp = 0.1\n",
    "        for i in range(50):\n",
    "            for j in range(self.var_num):\n",
    "                self.pop_x[i][j] = random.uniform(self.bound[0][j], self.bound[1][j])\n",
    "                self.pop_v[i][j] = random.uniform(0, 1)\n",
    "            self.p_best[i] = self.pop_x[i]      # 储存最优的个体\n",
    "            fit = fitness(self.p_best[i])\n",
    "            if fit < temp:\n",
    "                self.g_best = self.p_best[i]\n",
    "                temp = fit\n",
    "    def update_operator(self, pop_size):\n",
    "        \"\"\"\n",
    "        更新算子：更新下一时刻的位置和速度\n",
    "        \"\"\"\n",
    "        c1 = 2     # 学习因子，一般为2\n",
    "        c2 = 2\n",
    "        w = 0.4    # 自身权重因子\n",
    "        for i in range(self.pop_size):\n",
    "            # 更新速度\n",
    "            self.pop_v[i] = w * self.pop_v[i] + c1 * random.uniform(0, 1) * (\n",
    "                        self.p_best[i] - self.pop_x[i]) + c2 * random.uniform(0, 1) * (self.g_best - self.pop_x[i])\n",
    "            # 更新位置\n",
    "            self.pop_x[i] = self.pop_x[i] + self.pop_v[i]\n",
    "            # 越界保护\n",
    "            for j in range(self.var_num):\n",
    "                if self.pop_x[i][j] < self.bound[0][j]:\n",
    "                    self.pop_x[i][j] = self.bound[0][j]\n",
    "                if self.pop_x[i][j] > self.bound[1][j]:\n",
    "                    self.pop_x[i][j] = self.bound[1][j]\n",
    "            # 更新p_best和g_best\n",
    "\n",
    "            if fitness(self.pop_x[i]) < fitness(self.p_best[i]):\n",
    "                self.p_best[i] = self.pop_x[i]\n",
    "                #print('size of g_best',self.g_best.size())\n",
    "            if fitness(self.pop_x[i]) < fitness(self.g_best):\n",
    "                self.g_best = self.pop_x[i]\n",
    " \n",
    "    def main(self):\n",
    "        popobj = []\n",
    "        self.ng_best = torch.zeros((1, self.var_num))[0]\n",
    "        for gen in range(self.iters):\n",
    "            self.update_operator(self.pop_size)\n",
    "            popobj.append(fitness(self.g_best))\n",
    "            print('############ Generation {} ############'.format(str(gen + 1)))\n",
    "            \n",
    "            if fitness(self.g_best) < fitness(self.ng_best):\n",
    "                self.ng_best = self.g_best.clone()\n",
    "            print('最好的位置：{}'.format(self.ng_best))\n",
    "            print('最小的loss：{}'.format(fitness(self.ng_best)))\n",
    "        print(\"---- End of (successful) Searching ----\")\n",
    " \n",
    "        plt.figure()\n",
    "        plt.title(\"Figure1\")\n",
    "        plt.xlabel(\"iterators\", size=14)\n",
    "        plt.ylabel(\"fitness\", size=14)\n",
    "        t = [t for t in range(self.iters)]\n",
    "        plt.plot(t, popobj.detach().numpy(), color='b', linewidth=2)\n",
    "        plt.show()\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    iters= 50\n",
    "    '''popsize = X_train.shape[0]'''\n",
    "    popsize=6441\n",
    "    low = [0.001]*6441\n",
    "    up = [10]*6441\n",
    "    parameters = [iters, popsize, low, up]\n",
    "    pso = PSO(parameters)\n",
    "    pso.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f24a138",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=pso.ng_best   #取出最优的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cece320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000e-03, 1.0000e-03, 2.5584e-02],\n",
      "        [1.6906e-03, 1.0000e-03, 1.8719e-03],\n",
      "        [5.1983e+00, 1.0000e-03, 1.8268e-03],\n",
      "        [1.0000e-03, 1.0000e-03, 1.0000e-03],\n",
      "        [1.8889e-03, 1.0000e-03, 5.7058e-03],\n",
      "        [4.1526e-02, 1.4891e-03, 1.0000e-03],\n",
      "        [1.0338e-02, 1.0000e-03, 1.0000e-03],\n",
      "        [1.0000e-03, 1.0000e-03, 1.0000e-03],\n",
      "        [1.0000e-03, 2.3218e-02, 1.0000e-03],\n",
      "        [1.9533e-01, 6.1434e-03, 1.5863e-02],\n",
      "        [5.6802e-03, 7.3034e-03, 1.8863e-03],\n",
      "        [2.9182e-03, 1.0000e-03, 1.0000e-03],\n",
      "        [3.2531e-03, 1.6211e-03, 1.6459e-03],\n",
      "        [1.0000e-03, 1.0000e-03, 1.0000e-03],\n",
      "        [1.0000e-03, 1.7915e-03, 1.0000e-03],\n",
      "        [1.0000e-03, 1.8966e-02, 1.6145e-03],\n",
      "        [4.0856e-02, 1.6615e-03, 1.0000e-03],\n",
      "        [1.0000e-03, 1.8663e-03, 1.0000e-03],\n",
      "        [1.0000e-03, 1.0000e-03, 1.6454e-03],\n",
      "        [1.9526e-01, 1.0000e-03, 1.3343e+00],\n",
      "        [1.0000e-03, 1.0000e-03, 5.1712e+00],\n",
      "        [1.0000e-03, 1.0000e-03, 6.5095e-03],\n",
      "        [1.0000e-03, 6.8178e-01, 6.0171e+00],\n",
      "        [1.0000e-03, 1.0000e-03, 2.2178e-01],\n",
      "        [1.0000e-03, 1.0000e-03, 1.0000e-03],\n",
      "        [3.7184e-03, 1.0593e-01, 1.0000e-03],\n",
      "        [1.0000e-03, 1.0000e-03, 1.0000e-03],\n",
      "        [1.6531e-03, 1.6963e-03, 1.7019e-03],\n",
      "        [1.0000e-03, 1.0000e-03, 1.2469e-02],\n",
      "        [1.0000e-03, 1.4363e-03, 1.0000e-03],\n",
      "        [1.0000e-03, 1.0000e-03, 3.2314e-01],\n",
      "        [1.9752e-03, 1.1378e-02, 1.0000e-03],\n",
      "        [9.7633e-03, 1.0000e-03, 1.6143e-03],\n",
      "        [1.0000e-03, 1.0000e-03, 1.0000e-03],\n",
      "        [1.0000e-03, 1.6637e-03, 1.6639e-03],\n",
      "        [3.3915e-01, 9.3162e-02, 1.0000e-03],\n",
      "        [1.9719e-03, 6.6316e-03, 3.5510e-02],\n",
      "        [1.0000e-03, 1.0000e-03, 1.7763e-01],\n",
      "        [1.0000e-03, 2.4502e-01, 1.0000e-03],\n",
      "        [1.0000e-03, 2.2755e-03, 1.7166e-03],\n",
      "        [2.6501e-03, 1.0000e-03, 3.9567e-02],\n",
      "        [3.5712e-02, 1.0000e-03, 1.0000e-03],\n",
      "        [1.7166e-03, 1.7212e-03, 9.1602e+00],\n",
      "        [4.7571e-03, 2.3379e-02, 1.0000e-03],\n",
      "        [1.0000e-03, 8.1207e-02, 4.3632e-03],\n",
      "        [8.8782e+00, 1.6983e-03, 1.0000e-03],\n",
      "        [1.8919e-03, 2.6454e-03, 1.7216e-03],\n",
      "        [3.2761e-03, 4.4861e+00, 9.1916e-01],\n",
      "        [1.0000e-03, 1.9574e-03, 1.6167e-03],\n",
      "        [1.8101e-03, 8.1753e-03, 6.4278e-03],\n",
      "        [1.0000e-03, 1.0000e-03, 1.0000e-03],\n",
      "        [2.0471e-03, 4.1033e-03, 1.0000e-03],\n",
      "        [1.8668e-03, 1.0000e-03, 1.7552e-03],\n",
      "        [1.0000e-03, 1.7669e-03, 5.2021e+00],\n",
      "        [1.0000e-03, 1.0000e-03, 1.0000e-03],\n",
      "        [1.0000e-03, 1.5896e-03, 1.0000e-03],\n",
      "        [1.6307e-03, 1.0000e-03, 1.0000e-03],\n",
      "        [1.9343e-03, 1.0000e-03, 2.9928e-03],\n",
      "        [1.0000e-03, 1.0000e-03, 3.5495e-03],\n",
      "        [1.0000e-03, 1.0000e-03, 2.7033e-02]])\n"
     ]
    }
   ],
   "source": [
    "torch.save(a,\"C:/Users/XHM/LEVIST/DIST/TFT_a_nosgd.pth\")    # 保存Tensor为pth文件\n",
    "b=torch.load(\"C:/Users/XHM/LEVIST/DIST/TFT_a_nosgd.pth\")   # 加载出这个参数\n",
    "\n",
    "import numpy\n",
    "#搭建MLP回归模型\n",
    "class MLPregression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLPregression,self).__init__()\n",
    "        p=b\n",
    "        self.input=nn.Linear(in_features=3,out_features=60,bias=True)\n",
    "        #定义第二个隐藏层\n",
    "        self.hidden2=nn.Linear(60,100)\n",
    "        #回归预测层\n",
    "        self.predict=nn.Linear(100,1)\n",
    "        \n",
    "        self.input.weight.data=p[0:180].reshape((60,3))\n",
    "        self.input.bias.data=p[180:240].reshape((60,))\n",
    "        self.hidden2.weight.data=p[240:6240].reshape((100,60))\n",
    "        self.hidden2.bias.data=p[6240:6340].reshape((100,))\n",
    "        self.predict.weight.data=p[6340:6440].reshape((1,100))\n",
    "        self.predict.bias.data=p[6440:6441]\n",
    "    def forward(self,x):\n",
    "        x=torch.tanh(self.input(x))\n",
    "        x=torch.tanh(self.hidden2(x))\n",
    "        output=self.predict(x)\n",
    "        return output[:,0]\n",
    "\n",
    "mlp=MLPregression()\n",
    "torch.save(mlp.state_dict(),\"C:/Users/XHM/LEVIST/DIST/TFT_init.pth\")    #保存模型的参数\n",
    "print(mlp.input.weight.data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
